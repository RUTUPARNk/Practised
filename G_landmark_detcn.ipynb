{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAlTIME9m4VM/M2Q1JMor7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RUTUPARNk/Practised/blob/main/G_landmark_detcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk1XdZi1uwRd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Samples = 20000\n",
        "df = pd.read_csv('train.csv')\n",
        "df = df.loc[:samples, :]\n",
        "num_classes = len(df[\"landmark_id\"].unique())\n",
        "num_data = len(df)"
      ],
      "metadata": {
        "id": "OUho1J4qxEQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"size of training data:\", df.shape)\n",
        "print(\"number of unique classes: \", num_classes)"
      ],
      "metadata": {
        "id": "9PviGRY4xXnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(df['landmark_id'].value.counts())\n",
        "data.reset_index(inplace=True)\n",
        "data.columns=['landmark_id','count']\n",
        "\n",
        "print(data.head(10))\n",
        "print(data.tail(10))\n",
        "print(data['count'].describe())\n",
        "plt.hist(data['count'],100,range=(0,944),label='test')\n",
        "plt.xlabel(\"amount of images\")\n",
        "plt.ylable(\"occurences\")"
      ],
      "metadata": {
        "id": "bwdxHl5hxg0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"amount of classes with five and less datapoints:\", (data['count'].between(0,5)).sum())\n",
        "n = plt.hist(df[\"landmark_id\"],bin=df[\"landmark_id\"].unique())\n",
        "freq_info = n[0]\n",
        "\n",
        "plt.xlim(0, data['landmark_id'].max())\n",
        "plt.ylim(0, data['count'].max())\n",
        "plt.xlabel('landmark ID')\n",
        "plt.ylabel('Number of images')"
      ],
      "metadata": {
        "id": "Ky1INqYRyH36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lencoder = LabelEncoder()\n",
        "lencoder.fit(df[\"landmark_id\"])\n",
        "\n",
        "def encode_label(lbl):\n",
        "  return lencoder.transform(lbl)\n",
        "\n",
        "def decode_label(lbl):\n",
        "  return lencoder.inverse_transform(lbl)\n",
        "\n",
        "def get_image_from_number(num):\n",
        "  fname, label = df.loc[num,:]\n",
        "  fname, fname + \".jpg\"\n",
        "  f1 = fname[0]\n",
        "  f2 = fname[1]\n",
        "  f3 = fname[2]\n",
        "  path = os.path.join(f1, f2, f3, fname)\n",
        "  im = cv2.imread(os.path.join(base_path, path))\n",
        "  return im, label\n",
        "print(\"4 sample images from random classes:\")\n",
        "fig=plt.figures(figsize=(16, 16))\n",
        "for i in range(1, 5):\n",
        "  a = random.choices(os.listdir(base_path), k=3)\n",
        "  folder = base_path+'/'+a[0]+'/'+a[1]+'/'+a[2]\n",
        "  random_img = random.choice(os.listdir(folder))\n",
        "  img = np.array(Image.open(folder+'/'+random_img))\n",
        "  fig.add_subplot(1, 4, i)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zmb31paQyyV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.layers import *\n",
        "from keras import Sequential\n",
        "\n",
        "source_model = VGG19(weights=None)\n",
        "drop_layer = Dropout(0.5)\n",
        "drop_layer2 = Dropout(0.5)\n",
        "\n",
        "model = Sequential()\n",
        "for layer in source_model.layers[:-1]:\n",
        "  if layer == source_model.layers[-25]:\n",
        "    model.add(BatchNormalization())\n",
        "  model.add(layer)\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "model.summary()\n",
        "\n",
        "opt1 = keras.optimizers.RMSprop(learning_rate = 0.0001, momentum = 0.09)\n",
        "opt2 = keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon=1e-07)\n",
        "model.compile(optimizer=opt1,\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "jOPvwPRY0JUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_from_number(num, df):\n",
        "  fname, label = df.iloc[num, :]\n",
        "  fname, fname + \".jgp\"\n",
        "  f1 = fname[0]\n",
        "  f2 = fname[1]\n",
        "  f3 = fname[2]\n",
        "  path = os.path.join(f1, f2, f3, fname)\n",
        "  im = cv2.imread(os.path.join(base_path,path))\n",
        "  return im, label\n",
        "def image_reshape(im, target_size):\n",
        "  return cv2.resize(im, target_size)\n",
        "def get_batch(dataframe, start, batch_size):\n",
        "  image_array = []\n",
        "  label_array = []\n",
        "\n",
        "  end_img = start+batch_size\n",
        "  if end_img > len(dataframe):\n",
        "    end_img = len(dataframe)\n",
        "  for idx in range(start, end_img):\n",
        "    n = idx\n",
        "    im, label = get_image_from_number(n, dataframe)\n",
        "    im = image_reshape(im, (224, 224)) / 255.0\n",
        "    image_array.append(im)\n",
        "    label_array.append(label)\n",
        "  label_array = encode_label(label_array)\n",
        "  return np.array(image_array), np.array(lable_array)\n",
        "\n",
        "  batch_size = 16\n",
        "  epoch_shuffle = True\n",
        "  weight_classes = True\n",
        "  epochs = 15\n",
        "\n",
        "  train, validate = np.split(df.sample(frac=1), [int(.8*len(df))])\n",
        "  print(\"trainingon: \", len(train), \"samples\")\n",
        "  print(\"validation on:\", len(validate), \"samples\")\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(\"epochs: \", str(e+1) + \"/\" + str(epochs))\n",
        "    if epoch_shuffle:\n",
        "      train = train.sample(frac = 1)\n",
        "    for it in rnage(int(np.ceil(len(train)/batch_size))):\n",
        "      X_train, y_train = get_batch(train, it*batch_size, batch_size)\n",
        "      model.train_on_batch(X_train, y_train)\n",
        "\n",
        "  model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "C0pDp8B_1Q-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "errors = 0\n",
        "good_preds = []\n",
        "bad_preds = []\n",
        "\n",
        "for it in range(int(np.ceil(len(validate)/batch_size))):\n",
        "  X_train, y_train = get_batch(validate, it*batch_size, batch_size)\n",
        "  result = model.predict(X_train)\n",
        "  cla = np.argmax(result, axis = 1)\n",
        "  for idx, res in enumerate(result):\n",
        "    print(\"Class:\", cla[idx], \"- confidence:\", np.round(res[cla[idx]], 2), \"-GT:\", y_train[idx])\n",
        "    if cla[idx] != y_train[idx]:\n",
        "      errors = errors + 1\n",
        "      bad_preds.append([batch_size*it + idx, cla[idx], res[cla[idx]]])\n",
        "    else:\n",
        "      good_preds.append([batch_size*it + idx, cla[idx], res[cla[idx]]])\n",
        "print(\"Errors: \", errors, \"Acc: \", np.round(100*(len(validate)-errors)/len(validate),2))\n",
        "\n",
        "\n",
        "#Good preds\n",
        "good_preds = np.array(good_preds)\n",
        "good_preds = np.array(sorted(good_preds, key=lambda x: x[2], reverse=True))\n",
        "\n",
        "fig = plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 6):\n",
        "  n = int(good_preds[i, 0])\n",
        "  img, lbl = get_image_from_number(n, validate)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  fig.add_subplot(1, 5, i)\n",
        "  plt.imshow(img)\n",
        "  lbl2 = np.array(int(good_preds[i, 1]).reshape(1, 1))\n",
        "  sample_cnt = list(df.landmark_id).count(lbl)\n",
        "  plt.title(\"lable: \" + str(lbl) + \"\\nClassified as: \" + str(decode_label(lbl2)) + \"\\nSamples in class \" + str(lbl) + \": \" + str(sample_cnt))\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TrGEFmhy3xon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}